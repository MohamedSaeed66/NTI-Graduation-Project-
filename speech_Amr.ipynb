{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VDuAPctR0W2C"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def extract_audio(video_path, audio_path=\"audio.wav\"):\n",
        "    video = VideoFileClip(video_path)\n",
        "    video.audio.write_audiofile(\n",
        "        audio_path,\n",
        "        fps=16000,\n",
        "        codec=\"pcm_s16le\",\n",
        "        verbose=False,\n",
        "        logger=None\n",
        "    )\n",
        "    return audio_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeechTranscriber:\n",
        "    def __init__(self):\n",
        "        self.asr = pipeline(\n",
        "            \"automatic-speech-recognition\",\n",
        "            model=\"openai/whisper-large-v3\",\n",
        "            device=0\n",
        "        )\n",
        "\n",
        "    def transcribe(self, video_path):\n",
        "        audio_path = extract_audio(video_path)\n",
        "        result = self.asr(audio_path)\n",
        "        return result[\"text\"]"
      ],
      "metadata": {
        "id": "4D4oQOgO0c99"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "# class AnswerEvaluator:\n",
        "#     def __init__(self, llm_pipeline):\n",
        "#         self.llm = llm_pipeline\n",
        "\n",
        "#     def evaluate(self, transcript, question):\n",
        "#         prompt = f\"\"\"\n",
        "# You are a senior technical interview evaluator.\n",
        "\n",
        "# Evaluate the candidate answer strictly based on the question.\n",
        "# Return ONLY one valid JSON object. No extra text.\n",
        "\n",
        "# Question: \"{question}\"\n",
        "# Candidate Answer: \"{transcript}\"\n",
        "\n",
        "# JSON format:\n",
        "# {{\n",
        "#   \"scores\": {{\n",
        "#     \"technical_accuracy\": 0,\n",
        "#     \"relevance\": 0,\n",
        "#     \"depth_of_understanding\": 0,\n",
        "#     \"applied_thinking\": 0,\n",
        "#     \"clarity\": 0,\n",
        "#     \"problem_solving\": 0,\n",
        "#     \"communication\": 0\n",
        "#   }},\n",
        "#   \"final_average_score\": 0.0,\n",
        "#   \"decision\": \"ACCEPT | REJECT\",\n",
        "#   \"strengths\": [],\n",
        "#   \"weaknesses\": [],\n",
        "#   \"improvement_suggestions\": []\n",
        "# }}\n",
        "# \"\"\"\n",
        "\n",
        "#         result = self.llm(prompt)[0][\"generated_text\"]\n",
        "\n",
        "#         try:\n",
        "#             start = result.find(\"{\")\n",
        "#             end = result.rfind(\"}\") + 1\n",
        "#             return json.loads(result[start:end])\n",
        "#         except Exception as e:\n",
        "#             return {\n",
        "#                 \"error\": \"Failed to parse JSON\",\n",
        "#                 \"raw_output\": result\n",
        "#             }"
      ],
      "metadata": {
        "id": "LPzevmxt0xDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "from dotenv import dotenv_values\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] =OPENAI_API_KEY = \"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\""
      ],
      "metadata": {
        "id": "BWRidmkZ4yul"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnswerEvaluator:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = OpenAI(api_key=api_key)\n",
        "\n",
        "    def evaluate(self, transcript, question):\n",
        "        transcript_clean = transcript.strip()\n",
        "        prompt = f\"\"\"\n",
        "You are a senior technical interview evaluation agent.\n",
        "\n",
        "Your task is to objectively evaluate a CANDIDATE'S ANSWER that was TRANSCRIBED FROM VIDEO (speech-to-text) in response to an AI-generated interview question.\n",
        "\n",
        "IMPORTANT TIME CONSTRAINT:\n",
        "- The candidate had a MAXIMUM of 2 MINUTES to answer.\n",
        "- Answers are expected to be concise.\n",
        "- Lack of deep implementation details, extended examples, or full trade-off analysis is NORMAL.\n",
        "- Do NOT penalize correct but brief explanations.\n",
        "\n",
        "Speech context:\n",
        "- The answer comes from spoken language.\n",
        "- Minor grammar issues, filler words, pauses, or informal phrasing are expected.\n",
        "- Ignore transcription artifacts and focus on meaning.\n",
        "\n",
        "Evaluation rules:\n",
        "- Evaluate ONLY what the candidate explicitly says.\n",
        "- Do NOT infer unstated knowledge.\n",
        "- Do NOT reward verbosity.\n",
        "- Penalize incorrect concepts, misunderstandings, or vague hand-waving.\n",
        "- Be consistent and conservative with high scores (9–10).\n",
        "\n",
        "Evaluation criteria (score EACH from 0 to 10):\n",
        "\n",
        "1. Technical Accuracy:\n",
        "   - Core concepts are correct and not misleading.\n",
        "\n",
        "2. Relevance:\n",
        "   - Directly answers the question without going off-topic.\n",
        "\n",
        "3. Depth of Understanding (Time-Aware):\n",
        "   - Shows correct conceptual understanding appropriate for a 2-minute answer.\n",
        "   - Deep details are optional.\n",
        "\n",
        "4. Applied Thinking:\n",
        "   - Mentions realistic techniques, tools, or system components.\n",
        "   - Personal experience is NOT required.\n",
        "\n",
        "5. Clarity:\n",
        "   - Explanation is logically structured and easy to follow.\n",
        "\n",
        "6. Reasoning & Problem Solving:\n",
        "   - Demonstrates cause–effect understanding or logical flow.\n",
        "\n",
        "7. Communication Quality:\n",
        "   - Clear, confident, professional interview delivery.\n",
        "\n",
        "Scoring instructions:\n",
        "- Use the FULL 0–10 range.\n",
        "- Scores of 9–10 require very strong clarity and correctness.\n",
        "- Do NOT inflate scores for generic or memorized answers.\n",
        "- Calculate the FINAL AVERAGE SCORE (rounded to 1 decimal place).\n",
        "\n",
        "Final decision rules (BINARY ONLY):\n",
        "- FINAL SCORE \\u2265 7.0 \\u2192 ACCEPT\n",
        "- FINAL SCORE < 7.0 \\u2192 REJECT\n",
        "\n",
        "Output rules:\n",
        "- Return JSON ONLY.\n",
        "- Do NOT include any decision other than ACCEPT or REJECT.\n",
        "Question: \"{question}\"\n",
        "Candidate Answer: \"{transcript_clean}\"\n",
        "\n",
        "Required JSON format:\n",
        "{{\n",
        "  \"scores\": {{\n",
        "    \"technical_accuracy\":0 ,\n",
        "    \"relevance\": ,\n",
        "    \"depth_of_understanding\": ,\n",
        "    \"applied_thinking\": ,\n",
        "    \"clarity\": ,\n",
        "    \"problem_solving\": ,\n",
        "    \"communication\":\n",
        "  }},\n",
        "  \"final_average_score\": ,\n",
        "  \"decision\": \"ACCEPT | REJECT\",\n",
        "  \"strengths\": [],\n",
        "  \"weaknesses\": [],\n",
        "  \"improvement_suggestions\": []\n",
        "}}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4.1\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a strict JSON-only evaluator.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Nxa19fyv4wQz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# video_path = \"x.mp4\"\n",
        "\n",
        "# # question\n",
        "# question = \"How would you improve the training stability of a neural network?\"\n",
        "\n",
        "# # 1) Transcription\n",
        "# transcriber = SpeechTranscriber()\n",
        "# transcript = transcriber.transcribe(video_path)\n",
        "\n",
        "# print(\"=== TRANSCRIPT ===\")\n",
        "# print(transcript)\n",
        "\n",
        "# # 2) Evaluation (من غير ما نبعت الفيديو تاني ❌)\n",
        "# evaluator = AnswerEvaluator(llm_pipeline)\n",
        "# evaluation = evaluator.evaluate(transcript, question)\n",
        "\n",
        "# print(\"=== EVALUATION ===\")\n",
        "# print(json.dumps(evaluation, indent=2))"
      ],
      "metadata": {
        "id": "b8b842zy0xGm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "video_path = \"/content/WIN_20260101_21_20_12_Pro.mp4\"\n",
        "question = \"explain what is overfitting?\"\n",
        "\n",
        "# 1) Transcription\n",
        "transcriber = SpeechTranscriber()\n",
        "transcript = transcriber.transcribe(video_path)\n",
        "\n",
        "print(\"=== TRANSCRIPT ===\")\n",
        "print(transcript)\n",
        "\n",
        "# 2) Evaluation with GPT-4.1\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"OpenAI API key not found. Please set it in the environment variable 'OPENAI_API_KEY' or directly provide it.\")\n",
        "\n",
        "evaluator = AnswerEvaluator(api_key=api_key)\n",
        "evaluation = evaluator.evaluate(transcript, question)\n",
        "\n",
        "print(\"=== EVALUATION ===\")\n",
        "print(json.dumps(json.loads(evaluation), indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfYdtskQ5VhZ",
        "outputId": "681dd8da-fed8-45af-9b2c-b6afe2661d1c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TRANSCRIPT ===\n",
            " Overfading is the model trained on the data too much and it's complex more than the usual.\n",
            "=== EVALUATION ===\n",
            "{\n",
            "  \"scores\": {\n",
            "    \"technical_accuracy\": 1,\n",
            "    \"relevance\": 3,\n",
            "    \"depth_of_understanding\": 1,\n",
            "    \"applied_thinking\": 0,\n",
            "    \"clarity\": 2,\n",
            "    \"problem_solving\": 0,\n",
            "    \"communication\": 2\n",
            "  },\n",
            "  \"final_average_score\": 1.3,\n",
            "  \"decision\": \"REJECT\",\n",
            "  \"strengths\": [\n",
            "    \"Attempted to relate overfitting to model complexity.\"\n",
            "  ],\n",
            "  \"weaknesses\": [\n",
            "    \"Incorrect terminology ('overfading' instead of 'overfitting').\",\n",
            "    \"Fails to explain the core concept of overfitting (poor generalization to new data).\",\n",
            "    \"No mention of realistic techniques, tools, or system components.\",\n",
            "    \"Lacks logical structure and clarity.\",\n",
            "    \"No demonstration of reasoning or problem-solving.\"\n",
            "  ],\n",
            "  \"improvement_suggestions\": [\n",
            "    \"Use the correct term: 'overfitting.'\",\n",
            "    \"Explain that overfitting occurs when a model learns the training data too well, including noise, and performs poorly on unseen data.\",\n",
            "    \"Mention that overfitting is often due to excessive model complexity relative to the amount of data.\",\n",
            "    \"Briefly describe how overfitting can be detected or mitigated (e.g., validation sets, regularization).\",\n",
            "    \"Structure the answer to clearly define the term and its implications.\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}